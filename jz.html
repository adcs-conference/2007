<html>
<body>

<h3>Measures of Measurements: Robust Evaluation of Search Systems</h3>

<p>A good search system is one that helps a user to find useful documents.
When building a new system, we hope, or hypothesise, that it will be more
effective than existing alternatives. We apply a measure, which is often a
drastic simplification, to establish whether the system is effective. Thus
the ability of the system to help users and the measurement of this ability
are only weakly connected, by assumptions that the researcher may not even
be aware of. But how robust are these assumptions? If they are poor, is the
research invalid? Such concerns apply not just to search, but to many other
data-processing tasks. In this talk I introduce some of the recent
developments in evaluation of search systems, and use these developments to
examine some of the assumptions that underlie much of the research in this
field.

<h3>About Justin Zobel</h3>

<p>Professor Justin Zobel is leading the Computing for Life Sciences
initiative within National ICT Australia's Victorian Laboratory. He
received his PhD from the University of Melbourne and for many years was
based in the School of CS&IT at RMIT University, where he led the Search
Engine group. He is an Editor-in-Chief of the International Journal of
Information Retrieval, an associate editor of ACM Transactions on
Information Systems and of Information Processing & Management, and was
until recently Treasurer of ACM SIGIR. In the research community, he is
best known for his role in the development of algorithms for efficient text
retrieval. He is the author of "Writing for Computer Science" and his
interests include search, bioinformatics, fundamental data structures, and
research methods.

</body>
</html>
